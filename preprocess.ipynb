{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocess.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_yQGy-dIkNV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import libraries\n",
        "\n",
        "import helpr\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc2NypHOIkF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_engg(df):\n",
        "    \n",
        "    # Remove irrelevant features\n",
        "    \n",
        "    df = df.drop(columns = ['start_date', 'start_station_code', 'end_date', 'end_station_code', 'duration_sec', 'is_member', 'month'])\n",
        "    \n",
        "    # Count bixi usage/number of trips based on relevant features - this is what we'll try to predict\n",
        "    \n",
        "    df['trip_count'] = df.groupby(['year', 'week_num', 'day_of_week', 'hour'], as_index=False).transform('count')['weather']\n",
        "    df = df.groupby(['year', 'week_num', 'day_of_week', 'hour'], as_index=False).agg('first')\n",
        "        \n",
        "    # Transform weather decription categories using one hot encoding\n",
        "    \n",
        "    enc = OneHotEncoder()\n",
        "    encoder = enc.fit_transform(df.weather.values.reshape(-1, 1)).toarray()\n",
        "    df_enc = pd.DataFrame(encoder, columns = [\"weather_\"+str(int(i)) for i in range(encoder.shape[1])])\n",
        "    df = pd.concat([df.drop(columns = ['weather']), df_enc], axis=1)\n",
        "    \n",
        "    print('Feature engineering complete.')\n",
        "    \n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbJKJ2ajRqsG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_test_splitting(df, test_year):\n",
        "    \n",
        "    # Split dataframe to train and test\n",
        "    \n",
        "    df_train = df[df['year'] != test_year]\n",
        "    df_test = df[df['year'] == test_year]\n",
        "    \n",
        "    df_train.drop(columns = ['year'])\n",
        "    df_test.drop(columns = ['year'])\n",
        "    \n",
        "    # Split dataframe to X and y    \n",
        "    \n",
        "    y_train = df_train.trip_count.values\n",
        "    X_train = df_train.drop(['trip_count'], axis=1)\n",
        "    \n",
        "    y_test = df_test.trip_count.values\n",
        "    X_test = df_test.drop(['trip_count'], axis=1)\n",
        "    \n",
        "    print('Train-test splitting complete.')\n",
        "    \n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrBrr4QMO44Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Using MinMaxScaler: It scales and translates each feature individually\n",
        "#such that it is in the given range on the training set, e.g. between zero and one.\n",
        "#It does not perform well in the presence of outliers.\n",
        "#X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
        "#X_scaled = X_std * (max - min) + min\n",
        "    \n",
        "\n",
        "def feature_norm(X_train, X_test, y_train, y_test):    \n",
        "    \n",
        "    scaler_X = MinMaxScaler()\n",
        "    scaler_y = MinMaxScaler()\n",
        "    \n",
        "    scaler_X.fit_transform(X_train)\n",
        "    X_train = scaler_X.transform(X_train)\n",
        "    X_test = scaler_X.transform(X_test)\n",
        "    \n",
        "    scaler_y.fit_transform(y_train.reshape(-1, 1))\n",
        "    y_train = scaler_y.transform(y_train.reshape(-1, 1))\n",
        "    y_test = scaler_y.transform(y_test.reshape(-1, 1))\n",
        "    \n",
        "    print('Feature normalization complete.')\n",
        "    \n",
        "    return X_train, X_test, y_train, y_test, scaler_y"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}